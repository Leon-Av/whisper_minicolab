{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwNJP0GKTKOTiFzEiBb7Kp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leon-Av/whisper_minicolab/blob/main/whisper_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка Whisper и необходимых зависимостей\n",
        "!pip install -U openai-whisper\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "import os\n",
        "import whisper\n",
        "import torch\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Виджет для выбора скорости\n",
        "speed_options = {\n",
        "    'fast': 'small',\n",
        "    'medium': 'medium',\n",
        "    'slow': 'large'\n",
        "}\n",
        "speed_dropdown = widgets.Dropdown(\n",
        "    options=[('Fast', 'fast'), ('Medium', 'medium'), ('Slow', 'slow')],\n",
        "    value='fast',\n",
        "    description='Speed:',\n",
        ")\n",
        "\n",
        "# Виджет для загрузки файла\n",
        "upload_widget = widgets.FileUpload(\n",
        "    accept='.mp3,.wav,.m4a,.mp4,.flac',  # поддерживаемые форматы\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "# Кнопка запуска\n",
        "run_button = widgets.Button(\n",
        "    description=\"Transcribe\",\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Вывод для отображения результатов\n",
        "output = widgets.Output()\n",
        "\n",
        "def transcribe_audio(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        if not upload_widget.value:\n",
        "            print(\"Пожалуйста, загрузите аудиофайл.\")\n",
        "            return\n",
        "        # Получаем имя и содержимое файла\n",
        "        uploaded_filename = list(upload_widget.value.keys())[0]\n",
        "        content = upload_widget.value[uploaded_filename]['content']\n",
        "        # Сохраняем файл\n",
        "        with open(uploaded_filename, 'wb') as f:\n",
        "            f.write(content)\n",
        "        # Определяем модель\n",
        "        model_size = speed_options[speed_dropdown.value]\n",
        "        # Проверяем доступность CUDA\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Выполняется команда: whisper {uploaded_filename} --model {model_size} --device {device}\")\n",
        "        # Загружаем и используем модель\n",
        "        model = whisper.load_model(model_size, device=device)\n",
        "        result = model.transcribe(uploaded_filename)\n",
        "        print(\"Результат распознавания:\")\n",
        "        print(result[\"text\"])\n",
        "\n",
        "run_button.on_click(transcribe_audio)\n",
        "\n",
        "# Отображаем виджеты\n",
        "display(speed_dropdown)\n",
        "display(upload_widget)\n",
        "display(run_button)\n",
        "display(output)\n"
      ],
      "metadata": {
        "id": "gRorGvgOqHiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}